---
layout: post
title:  mysql 技术内幕
date:   2019-09-27 08:00:00 +0800
categories: 基础
tag: 数据库
---

# 事务隔离级别 

* 脏读：更新还未提交，其他事务能读到更新后的
* 不可重复读：事物里对一条数据读两次，读到不一样的（修改）
* 幻读：事物里对结果集读两次，读到不一样的（新增和删除）


* READ_UNCOMMITTED   有脏读 不可重复读 幻读
* READ_COMMITTED   解决脏读 有不可重复读 幻读 (大多数默认 MyISAM)
* REPEATABLE_READ   解决不可重复读 有幻读 （InnoDB默认，可以用Next-Key Lock解决幻读）
* SERIALIZABLE   并发差

# 索引
* 覆盖索引
优先从辅助索引里找，数据量小(叶子只有id)，如 `select id/count(*) from table where other_index = xxx;`

* 不使用索引的情况，
除了一般说的is null, !=, like %xxx，外   
使用辅助索引查时，若查询结果为id外的且结果占整张表过大（一般20%）的会全表扫描    
因为使用辅助索引查到id后，要将这些id去聚集索引里找，这时为随机读，磁盘随机读一般较慢(固态会高一些)，mysql优化器会选择全表扫(顺序读)

* Index Hint(索引提示)
use/force/ignore index等

* Multi-Range Read (MRR)   
为了减少随机访问 （Explain中Extra字段显示 Using MRR），适用于range、ref、eq_ref类型的查询   
1 使得数据访问变得较为顺序，查询辅助索引时，先依据辅助索引查找的的主键重新排序，然后用排序好的的主键进行书签查找

* Index Collection Pushdown   
在存储引擎层就对数据进行过滤，减少sql层对数据的读取  （Explain中Extra字段显示 Using Index Condition）

[MySQL EXPLAIN详解](https://www.jianshu.com/p/ea3fc71fdc45)

# 锁
* S锁 共享锁（读锁） select ... lock in share mode;   
* X锁 排他锁（写锁） select ... for update;   
* IS IX 意向锁   
若对某一行加X锁，那么首先对对应数据库、表加IX锁，那么后面的想对表再加X/S，表上有IX锁，说明本表或行上有X锁在，就不要遍历每一行了

    | |IS|IX|S|X|
    |:---:|:---:|:---:|:---:|:---:|
    |IS|兼容|兼容|兼容|不兼容|
    |IX|兼容|兼容|不兼容|不兼容|
    |S|兼容|不兼容|兼容|不兼容|
    |X|不兼容|不兼容|不兼容|不兼容|

## 行锁算法   
Record Lock     单个行记录的锁（READ_COMMITTED级别默认）   
Gap Lock        间隙锁，锁一个区间，不包含边界   
Next-Key Lock   锁一个区间，包含边界（REPEATABLE_READ级别默认）   

在主键上查询 `select * from table where id = 1;`会聚集索引上加Record Lock
在辅助索引上查询 `select * from table where test_index = 1;`会在聚集索引上加Record Lock，辅助索引上加Next-Key Lock，
若test_index数据有(0,1,3)，区间为不包含边界的上下两个值(0,3)，所有在两个值时间再做插入(2)会阻塞

## 死锁发生例子
1. 两个事务先获取S锁，再进行写操作，X锁

    |T1|T2
    |:---:|:---:|
    |获取a表S锁          | 
    |                   | 获取a表S锁
    |修改数据  X锁（阻塞）   | 
    |                   | 修改数据 X锁（死锁抛异常，rollback）
    |修改成功   | 

2. 某个事务需要同时得到两个锁   

    |T1|T2
    |:---:|:---:|
    |获取行a X锁          | 
    |                   | 获取行b X锁
    |获取行b X锁（阻塞）   | 
    |                   | 获取行a X锁 （死锁抛异常，rollback）
    |获取两个锁 查询成功   | 

3. X 和 范围S锁

    |T1|T2
    |:---:|:---:|
    |select * from company_file where id = 2 for update;          | 
    |                   | select * from company_file where id < 20 lock in share mode;(阻塞，占了(*,2)的锁)
    |insert into company_file select 0; （死锁抛异常，rollback）  | 
    |                   | 查询成功 
   
    |T1|T2
    |:---:|:---:|
    |select * from company_file where id = 2 for update;          | 
    |                   | select * from company_file where id < 20 lock in share mode;(阻塞，占了(*,2)的锁)
    |insert into company_file select 19; （正常）  | 
    |insert into company_file select 0; （死锁，但正常提交，检测到了死锁，undo量大，将T2回滚）  | 
    |                   | 死锁抛异常，rollback 
  
    |T1|T2
    |:---:|:---:|
    |select * from company_file where id = 2 for update;          | 
    |insert into company_file select 0; （正常）  | 
    |                   | select * from company_file where id < 20 lock in share mode;(阻塞，占了(*,0)的锁)
    |insert into company_file select 1; （正常）  | 
    |insert into company_file select -1; （死锁，但正常提交）  | 
    |                   | 死锁抛异常，rollback 

死锁检测，wait-for graph，将等待的事务画图，若T1等T2，则画T1->T2，若同时T2->T1，成环，则回滚undo量最小的事务

## 锁升级
innodb 根据页进行加锁，资源(内存)开销小，不会进行锁升级   
若表有3 000 000数据页，每页100条数据   
若在数据上加锁，每个锁10字节，内存3G（sqlServer，升级为表锁）   
页上加锁，每个30字节，90M   

# mysql log
## redo log & bin log
* redo log，innodb的log，物理日志，存储引擎层的log，记录了“在某个数据页上做了什么修改”，
* bin log，server层的log，逻辑日志，记录了“操作的初始逻辑，upadte、insert、delete”

为什么会有redo log/bin log两份日志呢？

因为最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统——也就是redo log来实现crash-safe能力。

这两种日志有以下三点不同。

1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。

1. redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。

1. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

有了对这两个日志的概念性理解，我们再来看执行器和InnoDB引擎在执行这个简单的update语句时的内部流程。

1. 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。

1. 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。

1. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。

1. 执行器生成这个操作的binlog，并把binlog写入磁盘。

1. 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。

## undo log
回滚日志，用于事物回滚操作，还有多版本并发控制（MVCC），解决不可重复读，读事物开始时的版本

## change buffer
* change buffer作用：   
当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作

* change buffer + redo log   
1若更新的数据页在内存，和chang buffer无关，直接更新内存，在磁盘写入上述的redo log和bin log，事务提交   
2更新的数据未在内存，在内存的change buffer区域，记录下“Page xx修改成了page xx'”这个信息，同样在磁盘写入的redo log和bin log   
若需要读修改的数据时，先读入磁盘数据，再进行change buffer操作得到最后的数据

redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。   
修改唯一索引时，因为要检测数据唯一性，需要先读入磁盘，所以change buffer失效 
